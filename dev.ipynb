{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b487e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import einops as eo\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6681abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iterable2DPoints(Dataset):\n",
    "    def __init__(self, means=torch.tensor([[-2,2], [2, 2], [0, -2]]), \n",
    "                       stds=torch.tensor([0.2, 0.1, 0.3]), \n",
    "                       weight=torch.tensor([1/3,1/3,1/3]), \n",
    "                       n=int(1e12)):\n",
    "        super().__init__()\n",
    "        self.means = means\n",
    "        self.stds = stds\n",
    "        self.weight = weight\n",
    "        self.borders = []\n",
    "        for w in weight:\n",
    "            if len(self.borders) == 0:\n",
    "                self.borders += [w]\n",
    "            else:\n",
    "                self.borders += [w+self.borders[-1]]\n",
    "        self.borders = torch.tensor(self.borders)\n",
    "        self.n=n\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        rnd = torch.rand(1)[0].item()\n",
    "        for idx, border in enumerate(self.borders):\n",
    "            if rnd < border:\n",
    "                return torch.randn(2)*self.stds[idx]+self.means[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5d86c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Iterable2DPoints()\n",
    "iterator = iter(dataset)\n",
    "X = []\n",
    "for i in tqdm(range(100)):\n",
    "    x = next(iterator)\n",
    "    X += [x]\n",
    "X = torch.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viz(X):\n",
    "    plt.scatter(X[:,0],X[:,1])\n",
    "    plt.show()\n",
    "\n",
    "viz(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d186988",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePositionalEncoding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        return torch.cat([x,t],dim=1)\n",
    "\n",
    "\n",
    "class SimpleFlowMatcher(nn.Module):\n",
    "    def __init__(self, d_data=2, d_model=64, act_fn=F.gelu):\n",
    "        super().__init__()\n",
    "        self.d_data = d_data\n",
    "        self.d_model = d_model\n",
    "        self.up_proj = nn.Linear(self.d_data+1, self.d_model)\n",
    "        self.up_gate = nn.Linear(self.d_data+1, self.d_model)\n",
    "        self.body = nn.Linear(self.d_model, self.d_model)\n",
    "        self.down_proj = nn.Linear(self.d_model, self.d_data)\n",
    "        self.act_fn = act_fn\n",
    "        self.pe = SimplePositionalEncoding()\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        x = self.pe(x, t)\n",
    "        h1 = self.up_proj(x)\n",
    "        h2 = self.up_gate(x)\n",
    "        h = h1*self.act_fn(h2, inplace=True)\n",
    "        #h = self.body(h)\n",
    "        #h = self.act_fn(h, inplace=True)\n",
    "        v = self.down_proj(h)\n",
    "        return v\n",
    "\n",
    "class SimpleFlowMatcherPlusLoss(nn.Module):\n",
    "    def __init__(self, d_data=2, d_model=64, act_fn=F.leaky_relu):\n",
    "        super().__init__()\n",
    "        self.v = SimpleFlowMatcher(d_data=d_data, d_model=d_model, act_fn=act_fn)\n",
    "    \n",
    "    def forward(self, x, t, v_gt):\n",
    "        v_pred = self.v(x, t)\n",
    "        loss = F.mse_loss(v_pred, v_gt)\n",
    "        return {'loss':loss, 'pred':v_pred}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a15ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = t.rand(100)*2 - 1\n",
    "#y = t.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e651831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleFlowMatcherPlusLoss()\n",
    "device = 'mps'\n",
    "model.to(device)\n",
    "t = F.sigmoid(torch.rand(1, device=device))\n",
    "eps = torch.randn(2, device=device)\n",
    "x = x.to(device)\n",
    "v = x - eps\n",
    "x_t = x - t*v\n",
    "out = model(x_t.unsqueeze(0), t.unsqueeze(0), v.unsqueeze(0))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf73e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "class Logger():\n",
    "    def __init__(self):\n",
    "        self.logs = defaultdict(list)\n",
    "    \n",
    "    def log(self, key, val):\n",
    "        self.logs[key] += [val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e5095",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1000).msort()\n",
    "t = F.sigmoid(x)\n",
    "plt.plot(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(v, x, num_steps=10, uniform=True, device=device):\n",
    "    if uniform: \n",
    "        ts = 1 - torch.linspace(0, 1, num_steps, device=device)\n",
    "    else:\n",
    "        ts = 1 - F.sigmoid(torch.randn(num_steps, device=device).msort())\n",
    "    #print(ts)\n",
    "    x_prev = x.clone()\n",
    "    for i in tqdm(range(len(ts)-1)):\n",
    "        x_prev = x_prev + (ts[i] - ts[i+1])*v(x_prev, ts[i]) \n",
    "    return x_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d7ce6",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a97cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform = False\n",
    "n_steps = 1000\n",
    "lr = 1e-3\n",
    "min_lr = 0\n",
    "weight_decay = 1e-7\n",
    "batch_size = 512 # 2**9 -> 2000\n",
    "model = SimpleFlowMatcherPlusLoss(d_model=512)\n",
    "device = 'mps'\n",
    "model.to(device)\n",
    "dataset = Iterable2DPoints()\n",
    "loader = DataLoader(dataset, batch_size=batch_size)\n",
    "opt = torch.optim.AdamW(params=model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "#scheduler = torch.optim.lr_scheduler.LinearLR(optimizer=opt, total_iters=n_steps)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer=opt, T_max=n_steps)\n",
    "logger = Logger()\n",
    "iterator = iter(loader)\n",
    "\n",
    "pbar = tqdm(range(n_steps))\n",
    "for i in pbar:\n",
    "    opt.zero_grad()\n",
    "    x = next(iterator)\n",
    "    x = x.to(device)\n",
    "    if uniform: \n",
    "        t = torch.rand((x.shape[0], 1), device=device)\n",
    "    else:\n",
    "        t = F.sigmoid(torch.randn((x.shape[0], 1), device=device))\n",
    "    eps = torch.randn((x.shape[0], 2), device=device)\n",
    "    v = x - eps\n",
    "    x_t = x - t*v\n",
    "    out = model(x_t, t, v)\n",
    "    loss = out['loss']\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.1)\n",
    "    opt.step()\n",
    "    scheduler.step()\n",
    "    logger.log('loss', loss.item())\n",
    "    curr_lr = opt.param_groups[0]['lr']\n",
    "    logger.log('lr', curr_lr)\n",
    "    pbar.set_postfix_str(f'loss {loss.item():.4f} lr {curr_lr:.4f}')\n",
    "    \n",
    "\n",
    "plt.plot(logger.logs['loss'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfcf518",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(v, x, num_steps=10, uniform=True, device=device):\n",
    "    if uniform: \n",
    "        ts = 1 - torch.linspace(0, 1, num_steps, device=device)\n",
    "    else:\n",
    "        ts = 1 - F.sigmoid(torch.randn(num_steps, device=device).msort())\n",
    "    #print(ts)\n",
    "    x_prev = x.clone()\n",
    "    for i in tqdm(range(len(ts)-1)):\n",
    "        t_cond = ts[i].repeat(x_prev.shape[0], 1)\n",
    "        x_prev = x_prev + (ts[i] - ts[i+1])*v(x_prev, t_cond) \n",
    "    return x_prev\n",
    "\n",
    "X_ = []\n",
    "for i in tqdm(range(20)):\n",
    "    x = sample(model.v, torch.randn((10, 2), device=device), num_steps=50, uniform=False)\n",
    "    X_ += [x.detach().cpu()]\n",
    "X_ = torch.cat(X_, dim=0)\n",
    "print(X_.shape)\n",
    "viz(X_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fb5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hexbin(X_[:, 0], X_[:, 1], gridsize=30, cmap='viridis')\n",
    "plt.colorbar(label='count in bin')\n",
    "plt.title('Hexbin map of X_')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
